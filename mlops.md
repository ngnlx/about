# ğŸ¤– MLOps & LLM Engineering

Covers the complete MLOps lifecycleâ€”from data ingestion and model training to deployment, monitoring, and continuous optimizationâ€”with an emphasis on reliability, scalability, and automation.

## Complete MLOps sample project

- ğŸ›’ [MLOps sample](https://github.com/ngnlx/mlops-sample): Complete MLOps system for e-commerce product recommendations. Demonstrates end-to-end solution that trains ML models to predict product recommendations based on user behavior and features, deploys models to production using Azure Kubernetes Service (AKS), monitors model performance to detect drift and maintain accuracy, and automates the entire workflow with CI/CD pipelines.

## Platform & Infrastructure

- ğŸ¤– **Azure AI Foundry**: Unified platform for building, deploying, and managing AI applications. Provides integrated tools for model development, fine-tuning, evaluation, and deployment with built-in safety and governance features.

## ğŸ”„ Data Pipelines & Orchestration

- ğŸ­ **Azure Data Factory (ADF)**: Cloud-based data integration service for creating, scheduling, and orchestrating data pipelines. Essential for ETL/ELT processes, data movement, and transformation workflows in ML/AI projects.

## ğŸ§± Serving & Inference

- ğŸ”Œ [LiteLLM sample](https://github.com/ngnlx/litellm-sample): lightweight gateway/proxy using the OpenAI-compatible API in front of multiple models/providers (ChatGPT/OpenAI, Azure OpenAI, Google Gemini, AWS Bedrock/Claude, â€¦). This sample is currently configured to run with Azure AI Foundry. Ideal for quick POCs, local dev, cost-aware routing, and swapping models with minimal (or zero) code changes.
